#!/usr/bin/env python3
"""
Reporter - Génération de rapports
"""

import json
from datetime import datetime
from typing import Dict, Any


class Reporter:
    def __init__(self):
        self.timestamp = datetime.now().isoformat()
    
    def generate_json_report(self, gatekeeper_result: Dict[str, Any], output_file: str = "pipeline_report.json") -> str:
        """Génère un rapport JSON"""
        report = {
            "timestamp": self.timestamp,
            "decision": gatekeeper_result["decision"],
            "risk_score": gatekeeper_result["risk_score"],
            "severity_counts": gatekeeper_result["severity_counts"],
            "total_issues": gatekeeper_result["total_issues"],
            "issues": gatekeeper_result["all_issues"]
        }
        
        with open(output_file, 'w') as f:
            json.dump(report, f, indent=2)
        
        return output_file
    
    def generate_markdown_report(self, gatekeeper_result: Dict[str, Any], output_file: str = "pipeline_report.md") -> str:
        """Génère un rapport Markdown"""
        decision = gatekeeper_result["decision"]
        risk_score = gatekeeper_result["risk_score"]
        severity_counts = gatekeeper_result["severity_counts"]
        issues_by_file = gatekeeper_result["issues_by_file"]
        
        # Badge pour la décision
        decision_badge = {
            "BLOCK": "[BLOCKED]",
            "WARN": "[WARNING]",
            "PASS": "[PASSED]"
        }
        
        md = f"""# Smart DevOps Pipeline Report

**Generated:** {self.timestamp}

## Decision: {decision_badge.get(decision, '')} {decision}

**Risk Score:** {risk_score}/100

**Message:** {gatekeeper_result['message']}

## Summary

| Severity | Count |
|----------|-------|
| Critical | {severity_counts.get('critical', 0)} |
| High     | {severity_counts.get('high', 0)} |
| Medium   | {severity_counts.get('medium', 0)} |
| Low      | {severity_counts.get('low', 0)} |
| **Total** | **{gatekeeper_result['total_issues']}** |

## Issues by File

"""
        
        for file_path, issues in issues_by_file.items():
            md += f"\n### {file_path}\n\n"
            
            for issue in issues:
                severity_badge = self._get_severity_badge(issue.get("severity", "unknown"))
                md += f"**{severity_badge} {issue.get('title', 'Unknown')}**\n\n"
                md += f"- **Line:** {issue.get('line', 'N/A')}\n"
                md += f"- **Description:** {issue.get('description', 'No description')}\n"
                
                if issue.get('recommendation'):
                    md += f"- **Recommendation:** {issue.get('recommendation')}\n"
                
                md += f"- **Confidence:** {issue.get('confidence', 1.0):.0%}\n"
                md += f"- **Type:** {issue.get('type', 'unknown')}\n\n"
        
        md += "\n---\n\n"
        md += "Generated by Smart DevOps Pipeline with AI-powered analysis\n"
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write(md)
        
        return output_file
    
    def _get_severity_badge(self, severity: str) -> str:
        """Retourne un badge pour la severity"""
        badges = {
            "critical": "[CRITICAL]",
            "high": "[HIGH]",
            "medium": "[MEDIUM]",
            "low": "[LOW]"
        }
        return badges.get(severity.lower(), "[UNKNOWN]")
    
    def generate_github_comment(self, gatekeeper_result: Dict[str, Any]) -> str:
        """Génère un commentaire formaté pour GitHub PR"""
        decision = gatekeeper_result["decision"]
        risk_score = gatekeeper_result["risk_score"]
        severity_counts = gatekeeper_result["severity_counts"]
        
        comment = f"""## Smart DevOps Pipeline Analysis

**Decision:** {decision}  
**Risk Score:** {risk_score}/100

### Issues Found

| Severity | Count |
|----------|-------|
| Critical | {severity_counts.get('critical', 0)} |
| High     | {severity_counts.get('high', 0)} |
| Medium   | {severity_counts.get('medium', 0)} |
| Low      | {severity_counts.get('low', 0)} |

"""
        
        if decision == "BLOCK":
            comment += "\n**Action Required:** Fix critical issues before merging.\n"
        elif decision == "WARN":
            comment += "\n**Warning:** Review and fix high/medium issues recommended.\n"
        else:
            comment += "\n**Status:** All checks passed!\n"
        
        # Ajouter top 5 issues
        all_issues = gatekeeper_result["all_issues"]
        critical_and_high = [i for i in all_issues if i.get("severity") in ["critical", "high"]]
        
        if critical_and_high:
            comment += "\n### Top Issues\n\n"
            for issue in critical_and_high[:5]:
                comment += f"- **[{issue.get('severity', '').upper()}]** {issue.get('title', 'Unknown')} in `{issue.get('file', 'unknown')}`\n"
        
        return comment


def main():
    """Test du reporter"""
    
    # Mock gatekeeper result
    mock_result = {
        "decision": "BLOCK",
        "risk_score": 75,
        "severity_counts": {
            "critical": 2,
            "high": 3,
            "medium": 5,
            "low": 1
        },
        "total_issues": 11,
        "message": "Deployment BLOCKED",
        "issues_by_file": {
            "terraform/iam.tf": [
                {
                    "severity": "critical",
                    "title": "IAM policy too permissive",
                    "description": "Wildcard in Action and Resource",
                    "line": 25,
                    "confidence": 0.95,
                    "type": "ai_terraform",
                    "recommendation": "Use specific actions and resources"
                }
            ]
        },
        "all_issues": [
            {
                "severity": "critical",
                "title": "IAM policy too permissive",
                "description": "Wildcard in Action and Resource",
                "file": "terraform/iam.tf",
                "line": 25,
                "confidence": 0.95,
                "type": "ai_terraform"
            }
        ]
    }
    
    reporter = Reporter()
    
    print("Generating reports...\n")
    
    json_file = reporter.generate_json_report(mock_result)
    print(f"JSON report: {json_file}")
    
    md_file = reporter.generate_markdown_report(mock_result)
    print(f"Markdown report: {md_file}")
    
    print("\nGitHub Comment:")
    print(reporter.generate_github_comment(mock_result))


if __name__ == "__main__":
    main()
